{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f58be94-a89e-47b3-a1c2-fd41df571c74",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pip install flair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c81352f-a3a1-470d-92cd-bd835168c9bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\oumaima\\anaconda3\\lib\\site-packages (2.7.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\oumaima\\anaconda3\\lib\\site-packages (from torch) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\oumaima\\anaconda3\\lib\\site-packages (from torch) (4.14.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\oumaima\\anaconda3\\lib\\site-packages (from torch) (1.13.3)\n",
      "Requirement already satisfied: networkx in c:\\users\\oumaima\\anaconda3\\lib\\site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\oumaima\\anaconda3\\lib\\site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: fsspec in c:\\users\\oumaima\\anaconda3\\lib\\site-packages (from torch) (2025.5.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\oumaima\\anaconda3\\lib\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\oumaima\\anaconda3\\lib\\site-packages (from jinja2->torch) (2.1.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a2d9bfed-bc36-4638-9953-5a3b200c1e67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy==1.24.3 in c:\\users\\oumaima\\anaconda3\\lib\\site-packages (1.24.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install numpy==1.24.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6ebf77a3-e5b1-4000-ac09-48c1e1199166",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langdetect in c:\\users\\oumaima\\anaconda3\\lib\\site-packages (1.0.9)\n",
      "Requirement already satisfied: pymupdf in c:\\users\\oumaima\\anaconda3\\lib\\site-packages (1.26.1)\n",
      "Requirement already satisfied: six in c:\\users\\oumaima\\anaconda3\\lib\\site-packages (from langdetect) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install langdetect pymupdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4cb41478-8151-47ae-87cc-2d2bf48da470",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "\n\nIMPORTANT: PLEASE READ THIS FOR ADVICE ON HOW TO SOLVE THIS ISSUE!\n\nImporting the numpy C-extensions failed. This error can happen for\nmany reasons, often due to issues with your setup or how NumPy was\ninstalled.\n\nWe have compiled some common reasons and troubleshooting tips at:\n\n    https://numpy.org/devdocs/user/troubleshooting-importerror.html\n\nPlease note and check the following:\n\n  * The Python version is: Python3.11 from \"C:\\Users\\OUMAIMA\\anaconda3\\python.exe\"\n  * The NumPy version is: \"1.24.3\"\n\nand make sure that they are the versions you expect.\nPlease carefully study the documentation linked above for further help.\n\nOriginal error was: DLL load failed while importing _multiarray_umath: Le module spÃ©cifiÃ© est introuvable.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\numpy\\_core\\__init__.py:22\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 22\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m multiarray\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\numpy\\_core\\multiarray.py:11\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mfunctools\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _multiarray_umath, overrides\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_multiarray_umath\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m  \u001b[38;5;66;03m# noqa: F403\u001b[39;00m\n",
      "\u001b[1;31mImportError\u001b[0m: DLL load failed while importing _multiarray_umath: Le module spÃ©cifiÃ© est introuvable.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mfitz\u001b[39;00m  \u001b[38;5;66;03m# PyMuPDF\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangdetect\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m detect\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mflair\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01membeddings\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TransformerDocumentEmbeddings\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mflair\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Sentence\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mflair\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01membeddings\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TransformerDocumentEmbeddings\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\flair\\__init__.py:5\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpathlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Path\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m set_seed \u001b[38;5;28;01mas\u001b[39;00m hf_set_seed\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# global variable: cache_root\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\__init__.py:1816\u001b[0m\n\u001b[0;32m   1813\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_tensor\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Tensor  \u001b[38;5;66;03m# usort: skip\u001b[39;00m\n\u001b[0;32m   1815\u001b[0m \u001b[38;5;66;03m# needs to be after torch.Tensor is defined to avoid circular dependencies\u001b[39;00m\n\u001b[1;32m-> 1816\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m storage \u001b[38;5;28;01mas\u001b[39;00m storage  \u001b[38;5;66;03m# usort: skip\u001b[39;00m\n\u001b[0;32m   1817\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstorage\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m   1818\u001b[0m     _LegacyStorage,\n\u001b[0;32m   1819\u001b[0m     _StorageBase,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1822\u001b[0m     UntypedStorage,\n\u001b[0;32m   1823\u001b[0m )\n\u001b[0;32m   1826\u001b[0m \u001b[38;5;66;03m# NOTE: New <type>Storage classes should never be added. When adding a new\u001b[39;00m\n\u001b[0;32m   1827\u001b[0m \u001b[38;5;66;03m# dtype, use torch.storage.TypedStorage directly.\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\storage.py:27\u001b[0m\n\u001b[0;32m     23\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTypedStorage\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUntypedStorage\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 27\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m     29\u001b[0m     HAS_NUMPY \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\numpy\\__init__.py:153\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m polynomial\n\u001b[0;32m    152\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m random\n\u001b[1;32m--> 153\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ctypeslib\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ma\n\u001b[0;32m    155\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m matrixlib \u001b[38;5;28;01mas\u001b[39;00m _mat\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\numpy\\ctypeslib\\__init__.py:1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_ctypeslib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m      2\u001b[0m     __all__,\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;18m__doc__\u001b[39m,\n\u001b[0;32m      4\u001b[0m     _concrete_ndptr,\n\u001b[0;32m      5\u001b[0m     _ndptr,\n\u001b[0;32m      6\u001b[0m     as_array,\n\u001b[0;32m      7\u001b[0m     as_ctypes,\n\u001b[0;32m      8\u001b[0m     as_ctypes_type,\n\u001b[0;32m      9\u001b[0m     c_intp,\n\u001b[0;32m     10\u001b[0m     ctypes,\n\u001b[0;32m     11\u001b[0m     load_library,\n\u001b[0;32m     12\u001b[0m     ndpointer,\n\u001b[0;32m     13\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\numpy\\ctypeslib\\_ctypeslib.py:58\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m---> 58\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmultiarray\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mmu\u001b[39;00m\n\u001b[0;32m     59\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m set_module\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\numpy\\_core\\__init__.py:48\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m\n\u001b[0;32m     25\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m     26\u001b[0m \n\u001b[0;32m     27\u001b[0m \u001b[38;5;124mIMPORTANT: PLEASE READ THIS FOR ADVICE ON HOW TO SOLVE THIS ISSUE!\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;124m\"\"\"\u001b[39m \u001b[38;5;241m%\u001b[39m (sys\u001b[38;5;241m.\u001b[39mversion_info[\u001b[38;5;241m0\u001b[39m], sys\u001b[38;5;241m.\u001b[39mversion_info[\u001b[38;5;241m1\u001b[39m], sys\u001b[38;5;241m.\u001b[39mexecutable,\n\u001b[0;32m     47\u001b[0m         __version__, exc)\n\u001b[1;32m---> 48\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexc\u001b[39;00m\n\u001b[0;32m     49\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m envkey \u001b[38;5;129;01min\u001b[39;00m env_added:\n",
      "\u001b[1;31mImportError\u001b[0m: \n\nIMPORTANT: PLEASE READ THIS FOR ADVICE ON HOW TO SOLVE THIS ISSUE!\n\nImporting the numpy C-extensions failed. This error can happen for\nmany reasons, often due to issues with your setup or how NumPy was\ninstalled.\n\nWe have compiled some common reasons and troubleshooting tips at:\n\n    https://numpy.org/devdocs/user/troubleshooting-importerror.html\n\nPlease note and check the following:\n\n  * The Python version is: Python3.11 from \"C:\\Users\\OUMAIMA\\anaconda3\\python.exe\"\n  * The NumPy version is: \"1.24.3\"\n\nand make sure that they are the versions you expect.\nPlease carefully study the documentation linked above for further help.\n\nOriginal error was: DLL load failed while importing _multiarray_umath: Le module spÃ©cifiÃ© est introuvable.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import fitz  # PyMuPDF\n",
    "from langdetect import detect\n",
    "from flair.embeddings import TransformerDocumentEmbeddings\n",
    "from flair.data import Sentence\n",
    "from flair.embeddings import TransformerDocumentEmbeddings\n",
    "from flair.data import Sentence\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "sentence = Sentence(\"This is a test.\")\n",
    "embedding_model = TransformerDocumentEmbeddings('bert-base-uncased')\n",
    "embedding_model.embed(sentence)\n",
    "PDF_PATH = \"C:/Users/OUMAIMA/Downloads/cv_oumeymaFinal (1).pdf\"\n",
    "# Charger un modÃ¨le transformer de Flair (comme BERT)\n",
    "embedding_model = TransformerDocumentEmbeddings('bert-base-uncased')\n",
    "\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    \"\"\"Extract text from PDF using PyMuPDF.\"\"\"\n",
    "    text = \"\"\n",
    "    doc = fitz.open(pdf_path)\n",
    "    for page in doc:\n",
    "        page_text = page.get_text()\n",
    "        if page_text.strip():\n",
    "            text += page_text + \"\\n\"\n",
    "    doc.close()\n",
    "    return text\n",
    "\n",
    "def clean_text(text):\n",
    "    \"\"\"Clean text by replacing accented characters and removing special chars except \\n and spaces.\"\"\"\n",
    "    text = text.replace('Ã ', 'a').replace('Ã¢', 'a').replace('Ã¤', 'a')\n",
    "    text = text.replace('Ã©', 'e').replace('Ã¨', 'e').replace('Ãª', 'e').replace('Ã«', 'e')\n",
    "    text = text.replace('Ã®', 'i').replace('Ã¯', 'i')\n",
    "    text = text.replace('Ã´', 'o').replace('Ã¶', 'o')\n",
    "    text = text.replace('Ã¹', 'u').replace('Ã»', 'u').replace('Ã¼', 'u')\n",
    "    text = text.replace('Ã§', 'c')\n",
    "    text = re.sub(r'[^\\w\\s\\n]', '', text)\n",
    "    return text\n",
    "\n",
    "def detect_language(text):\n",
    "    \"\"\"Detect if the text is English or French with a larger sample and header check.\"\"\"\n",
    "    try:\n",
    "        sample = text[:1000].lower()\n",
    "        lang = detect(sample)\n",
    "        if re.search(r'\\b(formation|Ã©ducation|compÃ©tences|projets acadÃ©miques)\\b', sample):\n",
    "            return \"French\"\n",
    "        return \"French\" if lang == \"fr\" else \"English\" if lang == \"en\" else f\"Other ({lang})\"\n",
    "    except:\n",
    "        return \"Unknown\"\n",
    "\n",
    "def mock_flair_similarity(text1, text2):\n",
    "    \"\"\"Placeholder for flair similarity; use keyword overlap as a proxy with section-specific keywords.\"\"\"\n",
    "    # Define keywords for each section type\n",
    "    section_keywords = {\n",
    "        \"experience\": [\"worked\", \"developed\", \"experience\", \"team\", \"project\", \"intern\", \"built\"],\n",
    "        \"skills\": [\"skills\", \"languages\", \"frameworks\", \"proficient\", \"tools\", \"databases\"],\n",
    "        \"education\": [\"education\", \"degree\", \"graduated\", \"school\", \"university\", \"engineering\"]\n",
    "    }\n",
    "    # Use the appropriate keyword set based on section_type\n",
    "    keywords = section_keywords.get(section_type, section_keywords[\"experience\"])\n",
    "    text1_words = text1.lower().split()\n",
    "    text2_words = text2.lower().split()\n",
    "    common_words = set(text1_words) & set(text2_words) & set(keywords)\n",
    "    score = len(common_words) / len(keywords) if keywords else 0.0  # Normalized score [0, 1]\n",
    "    print(f\"Text1 words: {text1_words[:5]}... Text2 words: {text2_words[:5]}... Common: {common_words} (Keywords: {keywords})\")\n",
    "    return score\n",
    "def flair_similarity(text1, text2):\n",
    "    \"\"\"Compare deux textes en utilisant des embeddings contextuels Flair.\"\"\"\n",
    "    sentence1 = Sentence(text1)\n",
    "    sentence2 = Sentence(text2)\n",
    "\n",
    "    # GÃ©nÃ©rer les embeddings\n",
    "    embedding_model.embed(sentence1)\n",
    "    embedding_model.embed(sentence2)\n",
    "\n",
    "    # Extraire les vecteurs\n",
    "    vec1 = sentence1.embedding.detach().numpy()\n",
    "    vec2 = sentence2.embedding.detach().numpy()\n",
    "\n",
    "    # Cosine similarity entre les vecteurs\n",
    "    score = np.dot(vec1, vec2) / (np.linalg.norm(vec1) * np.linalg.norm(vec2))\n",
    "\n",
    "    return float(score)  # score entre -1 et 1\n",
    "def find_best_section_block(lines, standard_description, section_type=\"experience\"):\n",
    "    \"\"\"Find the best block for a given section (experience, skills, or education) by sliding a 5-line window and optimizing.\"\"\"\n",
    "    if len(lines) < 5:\n",
    "        return \"CV too short for 5-line window.\"\n",
    "\n",
    "    # Standard description for the specific section\n",
    "    standard_desc = standard_description.lower()\n",
    "\n",
    "    # Initialize sliding window\n",
    "    window_size = 5\n",
    "    best_start = 0\n",
    "    best_end = window_size\n",
    "    max_score = 0.0\n",
    "    current_start = 0\n",
    "\n",
    "    # Slide 5-line window across CV with debugging\n",
    "    print(f\"\\n=== SLIDING WINDOW PROCESS ({section_type.capitalize()}) ===\")\n",
    "    while current_start <= len(lines) - window_size:\n",
    "        window = \"\\n\".join(lines[current_start:current_start + window_size])\n",
    "        score = flair_similarity(window, standard_desc)\n",
    "        print(f\"Window {current_start}-{current_start + window_size}: {window[:50]}... (Score: {score:.2f})\")\n",
    "        if score > max_score:\n",
    "            max_score = score\n",
    "            best_start = current_start\n",
    "            best_end = current_start + window_size\n",
    "            print(f\"  -> New best window found! Score: {max_score:.2f}\")\n",
    "        current_start += 1\n",
    "\n",
    "    # Optimize window size around best 5-line block\n",
    "    best_block = \"\\n\".join(lines[best_start:best_end])\n",
    "    current_block = best_block\n",
    "    current_score = max_score\n",
    "    min_lines = 1\n",
    "    max_lines = len(lines)\n",
    "\n",
    "    print(f\"\\n=== WINDOW OPTIMIZATION ({section_type.capitalize()}) ===\")\n",
    "    print(f\"Initial best block ({best_end - best_start} lines):\\n{best_block}\")\n",
    "\n",
    "    # Expand or contract to find optimal length\n",
    "    while True:\n",
    "        # Try adding a line\n",
    "        if best_end < len(lines):\n",
    "            new_end = best_end + 1\n",
    "            new_block = \"\\n\".join(lines[best_start:new_end])\n",
    "            new_score = flair_similarity(new_block, standard_desc)\n",
    "            print(f\"Trying +1 line ({new_end - best_start} lines): {new_block[:50]}... (Score: {new_score:.2f})\")\n",
    "            if new_score > current_score:\n",
    "                current_block = new_block\n",
    "                current_score = new_score\n",
    "                best_end = new_end\n",
    "                print(f\"  -> Improved! New score: {current_score:.2f}\")\n",
    "            else:\n",
    "                print(f\"  -> No improvement, stopping expansion.\")\n",
    "                break\n",
    "        # Try removing a line from start if more than 5 lines\n",
    "        elif best_start < best_end - 1:\n",
    "            new_start = best_start + 1\n",
    "            new_block = \"\\n\".join(lines[new_start:best_end])\n",
    "            new_score = flair_similarity(new_block, standard_desc)\n",
    "            print(f\"Trying -1 line ({best_end - new_start} lines): {new_block[:50]}... (Score: {new_score:.2f})\")\n",
    "            if new_score >= current_score:\n",
    "                current_block = new_block\n",
    "                current_score = new_score\n",
    "                best_start = new_start\n",
    "                print(f\"  -> Improved! New score: {current_score:.2f}\")\n",
    "            else:\n",
    "                print(f\"  -> No improvement, stopping contraction.\")\n",
    "                break\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    return current_block, best_end - best_start\n",
    "\n",
    "# MAIN\n",
    "raw_text = extract_text_from_pdf(PDF_PATH)\n",
    "cleaned_text = clean_text(raw_text)\n",
    "lines = cleaned_text.splitlines()  # Split into lines here\n",
    "language = detect_language(raw_text)\n",
    "print(f\"\\nðŸ“„ Langue dÃ©tectÃ©e : {language}\")\n",
    "\n",
    "# Standard descriptions for each section\n",
    "standard_experience = \"Completed a 4-month internship at TechSolutions where I developed a RESTful API using Node.js and MongoDB, improving data processing.\"\n",
    "standard_skills = \"Proficient in Python, Java, JavaScript, and frameworks like Angular, with experience in databases such as MySQL and Firebase.\"\n",
    "standard_education = \"Graduated with a Bachelorâ€™s Degree in Computer Science from a university in 2023.\"\n",
    "\n",
    "# Detect blocks for each section\n",
    "best_experience_block, experience_line_count = find_best_section_block(lines, standard_experience, \"experience\")\n",
    "best_skills_block, skills_line_count = find_best_section_block(lines, standard_skills, \"skills\")\n",
    "best_education_block, education_line_count = find_best_section_block(lines, standard_education, \"education\")\n",
    "\n",
    "# Print results\n",
    "print(\"\\n=== SECTION D'EXPÃ‰RIENCE DÃ‰TECTÃ‰E ===\")\n",
    "print(f\"Best experience block:\\n{best_experience_block}\")\n",
    "print(f\"Number of lines: {experience_line_count}\")\n",
    "\n",
    "print(\"\\n=== SECTION DES COMPÃ‰TENCES DÃ‰TECTÃ‰E ===\")\n",
    "print(f\"Best skills block:\\n{best_skills_block}\")\n",
    "print(f\"Number of lines: {skills_line_count}\")\n",
    "\n",
    "print(\"\\n=== SECTION D'Ã‰DUCATION DÃ‰TECTÃ‰E ===\")\n",
    "print(f\"Best education block:\\n{best_education_block}\")\n",
    "print(f\"Number of lines: {education_line_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c77f0275-700b-4711-8dac-bad07ecd04df",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
